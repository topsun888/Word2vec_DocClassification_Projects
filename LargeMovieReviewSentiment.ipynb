{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文读取电影评论数据然后进行情感分类，主要利用词向量的概念。其主要思路和代码参考了CSDN博客[使用word2vec对新浪微博进行情感分析和分类](http://blog.csdn.net/liugallup/article/details/51164962)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#读取数据\n",
    "import os\n",
    "corpus_root = 'imdb/train'\n",
    "pos_dir = corpus_root+'/pos'\n",
    "neg_dir = corpus_root+'/neg'\n",
    "unsup_dir = corpus_root+'/unsup'\n",
    "def readDocs(directory):\n",
    "    reviews = []\n",
    "    fileids = os.listdir(directory)\n",
    "    for fileid in fileids:\n",
    "        path = directory + '/' + fileid\n",
    "        with open(path, encoding='utf8') as fi:\n",
    "            reviews.append(fi.read())\n",
    "    return reviews\n",
    "pos_reviews = readDocs(pos_dir)\n",
    "neg_reviews = readDocs(neg_dir)\n",
    "unsup_reviews = readDocs(unsup_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本预处理，给每段文字加上标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#use 1 for positive sentiment, 0 for negative\n",
    "y = np.concatenate((np.ones(len(pos_reviews)), np.zeros(len(neg_reviews))))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.concatenate((pos_reviews, neg_reviews)), y, test_size=0.2)\n",
    "\n",
    "#Do some very minor text preprocessing\n",
    "def cleanText(corpus):\n",
    "    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)\n",
    "unsup_reviews = cleanText(unsup_reviews)\n",
    "\n",
    "#Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "#We do this by using the LabeledSentence method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "#a dummy index of the review.\n",
    "def labelizeReviews(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizeReviews(x_train, 'TRAIN')\n",
    "x_test = labelizeReviews(x_test, 'TEST')\n",
    "unsup_reviews = labelizeReviews(unsup_reviews, 'UNSUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_corpus = []\n",
    "all_corpus.extend(x_train)\n",
    "all_corpus.extend(x_test)\n",
    "all_corpus.extend(unsup_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19264\n",
      "4817\n",
      "50000\n",
      "74081\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(unsup_reviews))\n",
    "print(len(all_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "size = 400\n",
    "\n",
    "#instantiate our DM and DBOW models\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, workers=3)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, dm=0, workers=3)\n",
    "\n",
    "#build vocab over all reviews\n",
    "model_dm.build_vocab(all_corpus)\n",
    "model_dbow.build_vocab(all_corpus)\n",
    "\n",
    "#We pass through the data set multiple times, shuffling the training reviews each time to improve accuracy.\n",
    "all_train_reviews = []\n",
    "all_train_reviews.extend(x_train)\n",
    "all_train_reviews.extend(unsup_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_train_reviews))\n",
    "np.hstack((a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ten epeochs\n",
    "for epoch in range(10):\n",
    "    model_dm.train(all_train_reviews)\n",
    "    model_dbow.train(all_train_reviews)\n",
    "\n",
    "#Fetch doc vector for each article\n",
    "def getVecs(model, tagged_corpus, size):\n",
    "    vecs = [model.docvecs[z.tags[0]].reshape((1, size)) for z in tagged_corpus]\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "train_vecs_dm = getVecs(model_dm, x_train, size)\n",
    "train_vecs_dbow = getVecs(model_dbow, x_train, size)\n",
    "\n",
    "train_vecs = np.hstack((train_vecs_dm, train_vecs_dbow))\n",
    "\n",
    "#train over test set\n",
    "#x_test = np.array(x_test)\n",
    "\n",
    "for epoch in range(10):\n",
    "    #perm = np.random.permutation(x_test.shape[0])\n",
    "    model_dm.train(x_test)\n",
    "    model_dbow.train(x_test)\n",
    "\n",
    "#Construct vectors for test reviews\n",
    "test_vecs_dm = getVecs(model_dm, x_test, size)\n",
    "test_vecs_dbow = getVecs(model_dbow, x_test, size)\n",
    "\n",
    "test_vecs = np.hstack((test_vecs_dm, test_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dm = getVecs(model_dm, x_train, size)\n",
    "train_vecs_dbow = getVecs(model_dbow, x_train, size)\n",
    "train_vecs = np.hstack((train_vecs_dm, train_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19264, 400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs_dbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19264,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "#model prediction\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss='log', penalty='l1')\n",
    "lr.fit(train_vecs, y_train)\n",
    "\n",
    "print('Test Accuracy: %.2f'%lr.score(test_vecs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
